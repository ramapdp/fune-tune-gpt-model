{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T16:18:10.700849Z",
     "start_time": "2024-07-18T16:18:10.695074Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import openai\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ],
   "id": "d301ce4c9b8c3cce",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Setup dataset",
   "id": "e1663401ddacc6a0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T15:19:06.516107Z",
     "start_time": "2024-07-18T15:19:06.499529Z"
    }
   },
   "cell_type": "code",
   "source": [
    "datasets = './data/dataset.jsonl'\n",
    "\n",
    "with open(datasets, 'r') as file:\n",
    "    for line_num, line in enumerate(file, 1):\n",
    "        try:\n",
    "            json.loads(line)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error in line {line_num}: {e}\")\n",
    "\n",
    "print(\"Format JSONL valid.\")"
   ],
   "id": "9db8e97e53a1a956",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Format JSONL valid.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T15:19:08.242854Z",
     "start_time": "2024-07-18T15:19:08.222105Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def validate_structure(dataset):\n",
    "    if not isinstance(dataset, dict):\n",
    "        return False\n",
    "    if \"messages\" not in dataset:\n",
    "        return False\n",
    "    if not isinstance(dataset[\"messages\"], list):\n",
    "        return False\n",
    "    for message in dataset[\"messages\"]:\n",
    "        if not isinstance(message, dict):\n",
    "            return False\n",
    "        if \"role\" not in message or \"content\" not in message:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "invalid_lines = []\n",
    "\n",
    "# Validate the structure of each line\n",
    "with open(datasets, 'r') as file:\n",
    "    for line_num, line in enumerate(file, 1):\n",
    "        data = json.loads(line)\n",
    "        if not validate_structure(data):\n",
    "            invalid_lines.append(line_num)\n",
    "\n",
    "if invalid_lines:\n",
    "    print(f\"Invalid structure in lines: {invalid_lines}\")\n",
    "else:\n",
    "    print(\"All data structures are valid.\")\n"
   ],
   "id": "a58af410b422db09",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All data structures are valid.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T15:19:09.855429Z",
     "start_time": "2024-07-18T15:19:09.802404Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Read JSONL file\n",
    "def read_jsonl(file_path):\n",
    "    data = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            data.append(json.loads(line))\n",
    "    return data\n",
    "\n",
    "\n",
    "# check_data_quality function\n",
    "def check_data_quality(data):\n",
    "    issues = []\n",
    "    for index, item in enumerate(data):\n",
    "        messages = item.get('messages', [])\n",
    "        if not messages:\n",
    "            issues.append(f\"Item {index}: 'messages' field is missing or empty.\")\n",
    "            continue\n",
    "        for msg in messages:\n",
    "            if 'role' not in msg or 'content' not in msg:\n",
    "                issues.append(f\"Item {index}: Missing 'role' or 'content' in message {msg}.\")\n",
    "            if msg['role'] not in ['system', 'user', 'assistant']:\n",
    "                issues.append(f\"Item {index}: Invalid role '{msg['role']}' in message {msg}.\")\n",
    "    return issues\n",
    "\n",
    "\n",
    "# Load data from JSONL file\n",
    "data = read_jsonl(datasets)\n",
    "\n",
    "# Check data quality\n",
    "issues = check_data_quality(data)\n",
    "\n",
    "# Display data quality issues\n",
    "if issues:\n",
    "    print(\"Data Quality Issues Found:\")\n",
    "    for issue in issues:\n",
    "        print(issue)\n",
    "else:\n",
    "    print(\"No data quality issues found.\")\n",
    "\n",
    "# Convert data to DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(df.head())\n",
    "\n",
    "# Display the number of messages in each conversation\n",
    "df['message_count'] = df['messages'].apply(len)\n",
    "print(df['message_count'].describe())\n",
    "\n",
    "# Display the distribution of message counts\n",
    "message_lengths = []\n",
    "for item in data:\n",
    "    for msg in item['messages']:\n",
    "        message_lengths.append(len(msg['content']))\n",
    "\n",
    "message_lengths_series = pd.Series(message_lengths)\n",
    "print(message_lengths_series.describe())\n"
   ],
   "id": "d28511148db92c73",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data quality issues found.\n",
      "                                            messages\n",
      "0  [{'role': 'system', 'content': 'Anda adalah AI...\n",
      "1  [{'role': 'system', 'content': 'Anda adalah AI...\n",
      "2  [{'role': 'system', 'content': 'Anda adalah AI...\n",
      "3  [{'role': 'system', 'content': 'Anda adalah AI...\n",
      "4  [{'role': 'system', 'content': 'Anda adalah AI...\n",
      "count    250.0\n",
      "mean       3.0\n",
      "std        0.0\n",
      "min        3.0\n",
      "25%        3.0\n",
      "50%        3.0\n",
      "75%        3.0\n",
      "max        3.0\n",
      "Name: message_count, dtype: float64\n",
      "count    750.000000\n",
      "mean     160.486667\n",
      "std      101.120936\n",
      "min       24.000000\n",
      "25%       71.500000\n",
      "50%      182.000000\n",
      "75%      209.000000\n",
      "max      949.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Split the dataset into training, validation, and test sets",
   "id": "7dc525cc598ed409"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T15:19:13.555357Z",
     "start_time": "2024-07-18T15:19:13.522405Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_train = './data/data_train.jsonl'\n",
    "data_validation = './data/data_validation.jsonl'\n",
    "data_test = './data/data_test.jsonl'\n",
    "\n",
    "\n",
    "# Load data from JSONL file\n",
    "def load_jsonl(filename):\n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        return [json.loads(line) for line in f]\n",
    "\n",
    "\n",
    "data = load_jsonl(datasets)\n",
    "\n",
    "# Shuffle data\n",
    "random.shuffle(data)\n",
    "\n",
    "# Define split ratios\n",
    "train_ratio = 0.8  # 80% training\n",
    "validation_ratio = 0.1  # 10% validation\n",
    "test_ratio = 0.1  # 10% testing\n",
    "\n",
    "# Calculate split indices\n",
    "train_index = int(len(data) * train_ratio)\n",
    "validation_index = train_index + int(len(data) * validation_ratio)\n",
    "\n",
    "# Split data into training, validation, and testing sets\n",
    "train_data = data[:train_index]\n",
    "validation_data = data[train_index:validation_index]\n",
    "test_data = data[validation_index:]\n",
    "\n",
    "\n",
    "# Save data to JSONL file\n",
    "def save_jsonl(data, filename):\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        for entry in data:\n",
    "            f.write(json.dumps(entry) + '\\n')\n",
    "\n",
    "\n",
    "# Save training, validation, and testing data\n",
    "save_jsonl(train_data, data_train)\n",
    "save_jsonl(validation_data, data_validation)\n",
    "save_jsonl(test_data, data_test)\n",
    "\n",
    "print(f\"Training data saved to {data_train}\")\n",
    "print(f\"Validation data saved to {data_validation}\")\n",
    "print(f\"Testing data saved to {data_test}\")\n"
   ],
   "id": "a4f6ab49a4cdfd51",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data saved to ./data/data_train.jsonl\n",
      "Validation data saved to ./data/data_validation.jsonl\n",
      "Testing data saved to ./data/data_test.jsonl\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Estimate the cost of fine-tuning",
   "id": "5fd6a6a6489a9cf1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T15:19:15.876362Z",
     "start_time": "2024-07-18T15:19:15.827410Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define a function to estimate the cost of fine-tuning\n",
    "def estimate_fine_tuning_cost(file_path, model=\"gpt-3.5-turbo\"):\n",
    "    # Define the cost parameters\n",
    "    cost_per_token = 8.00 / 1_000_000  # Cost per token (e.g., $8.00 per 1M tokens for GPT-3.5 Turbo)\n",
    "    cost_per_fine_tune = 8.00 / 1_000_000  # Assuming the fine-tuning cost is the same (adjust if necessary)\n",
    "\n",
    "    # Load the data\n",
    "    with open(file_path, \"r\") as file:\n",
    "        data = [json.loads(line) for line in file]\n",
    "\n",
    "    # Function to count tokens in a message\n",
    "    def count_tokens(messages):\n",
    "        return sum(len(message['content'].split()) for message in messages)\n",
    "\n",
    "    # Calculate the total number of tokens in the dataset\n",
    "    total_tokens = sum(count_tokens(example[\"messages\"]) for example in data)\n",
    "\n",
    "    # Estimate the cost\n",
    "    training_cost = total_tokens * cost_per_fine_tune\n",
    "    usage_cost = total_tokens * cost_per_token\n",
    "\n",
    "    total_cost = training_cost + usage_cost\n",
    "\n",
    "    return total_tokens, training_cost, usage_cost, total_cost\n",
    "\n",
    "\n",
    "# Estimate the cost\n",
    "total_tokens, training_cost, usage_cost, total_cost = estimate_fine_tuning_cost(data_train)\n",
    "\n",
    "# Display the results\n",
    "print(f\"Total Tokens: {total_tokens}\")\n",
    "print(f\"Training Cost: ${training_cost:.2f}\")\n",
    "print(f\"Usage Cost: ${usage_cost:.2f}\")\n",
    "print(f\"Total Estimated Cost: ${total_cost:.2f}\")"
   ],
   "id": "ce0b564e855d2f5a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Tokens: 12699\n",
      "Training Cost: $0.10\n",
      "Usage Cost: $0.10\n",
      "Total Estimated Cost: $0.20\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Upload data to OpenAI",
   "id": "ed31bca866b15244"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T15:19:19.317402Z",
     "start_time": "2024-07-18T15:19:19.285547Z"
    }
   },
   "cell_type": "code",
   "source": [
    "load_dotenv(dotenv_path='./apiKey.env')\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "client = OpenAI(api_key=openai_api_key)"
   ],
   "id": "5decd614b5c551e6",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T15:20:24.903824Z",
     "start_time": "2024-07-18T15:20:23.686008Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Upload the training data\n",
    "training_response = client.files.create(\n",
    "    purpose='fine-tune',\n",
    "    file=open(data_train, 'rb'),\n",
    ")\n",
    "\n",
    "training_file_id = training_response.id\n",
    "print(\"Training file id:\", training_file_id)"
   ],
   "id": "36bbf9498cb8c71a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training file id: file-kn0GWfMTqzbIaCNCLPHjEnNw\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T15:20:27.766447Z",
     "start_time": "2024-07-18T15:20:26.973755Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Upload the validation data\n",
    "validation_response = client.files.create(\n",
    "    purpose='fine-tune',\n",
    "    file=open(data_validation, 'rb'),\n",
    ")\n",
    "\n",
    "validation_file_id = validation_response.id\n",
    "print(\"Validation file id:\", validation_file_id)"
   ],
   "id": "ef56c05a158956b9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation file id: file-NPRe3mhUVSNJamKi09cioEP5\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T15:20:29.993361Z",
     "start_time": "2024-07-18T15:20:29.988847Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Upload the test data\n",
    "# test_response = client.files.create(\n",
    "#     purpose='fine-tune',\n",
    "#     file=open(data_test, 'rb'),\n",
    "# )\n",
    "# \n",
    "# test_file_id = test_response.id\n",
    "# print(\"Test file id:\", test_file_id)"
   ],
   "id": "41a4f010a139686f",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Fine-tune model with new data",
   "id": "353e03f2d5bc13cc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T15:20:40.064495Z",
     "start_time": "2024-07-18T15:20:37.276368Z"
    }
   },
   "cell_type": "code",
   "source": [
    "fine_tune_response = client.fine_tuning.jobs.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    training_file=training_file_id,\n",
    "    validation_file=validation_file_id,\n",
    "    suffix=\"bpa_itpln\",\n",
    "    hyperparameters={   \n",
    "        \"n_epochs\": \"auto\",\n",
    "        \"batch_size\": \"auto\",\n",
    "        \"learning_rate_multiplier\": \"auto\"\n",
    "    }\n",
    ")\n",
    "\n",
    "fine_tune_id = fine_tune_response.id\n",
    "\n",
    "print(f\"Fine-tuning started with ID: {fine_tune_id}\")\n",
    "print(fine_tune_response)"
   ],
   "id": "849aa25bb4a988b8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning started with ID: ftjob-Zjs25G0yacSbt2mTXsf623YP\n",
      "FineTuningJob(id='ftjob-Zjs25G0yacSbt2mTXsf623YP', created_at=1721316039, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-lv4C6T43m3ZXCtmBwhwKWPU5', result_files=[], seed=1460983493, status='validating_files', trained_tokens=None, training_file='file-kn0GWfMTqzbIaCNCLPHjEnNw', validation_file='file-NPRe3mhUVSNJamKi09cioEP5', estimated_finish=None, integrations=[], user_provided_suffix='bpa_itpln')\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Monitor the fine-tuning process",
   "id": "6c6179eac8fe6227"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T15:52:12.436386Z",
     "start_time": "2024-07-18T15:20:45.999636Z"
    }
   },
   "cell_type": "code",
   "source": [
    "while True:\n",
    "    status_response = client.fine_tuning.jobs.retrieve(fine_tune_id)\n",
    "    print(status_response)\n",
    "    if status_response.status == 'succeeded':\n",
    "        break\n",
    "    time.sleep(60)  # Check every minute\n",
    "\n",
    "# Get the fine-tuned model ID\n",
    "result_response = client.fine_tuning.jobs.retrieve(fine_tune_id)\n",
    "print(result_response)"
   ],
   "id": "74ed51b2dcd324a2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FineTuningJob(id='ftjob-Zjs25G0yacSbt2mTXsf623YP', created_at=1721316039, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-lv4C6T43m3ZXCtmBwhwKWPU5', result_files=[], seed=1460983493, status='validating_files', trained_tokens=None, training_file='file-kn0GWfMTqzbIaCNCLPHjEnNw', validation_file='file-NPRe3mhUVSNJamKi09cioEP5', estimated_finish=None, integrations=[], user_provided_suffix='bpa_itpln')\n",
      "FineTuningJob(id='ftjob-Zjs25G0yacSbt2mTXsf623YP', created_at=1721316039, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-lv4C6T43m3ZXCtmBwhwKWPU5', result_files=[], seed=1460983493, status='queued', trained_tokens=None, training_file='file-kn0GWfMTqzbIaCNCLPHjEnNw', validation_file='file-NPRe3mhUVSNJamKi09cioEP5', estimated_finish=None, integrations=[], user_provided_suffix='bpa_itpln')\n",
      "FineTuningJob(id='ftjob-Zjs25G0yacSbt2mTXsf623YP', created_at=1721316039, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-lv4C6T43m3ZXCtmBwhwKWPU5', result_files=[], seed=1460983493, status='queued', trained_tokens=None, training_file='file-kn0GWfMTqzbIaCNCLPHjEnNw', validation_file='file-NPRe3mhUVSNJamKi09cioEP5', estimated_finish=None, integrations=[], user_provided_suffix='bpa_itpln')\n",
      "FineTuningJob(id='ftjob-Zjs25G0yacSbt2mTXsf623YP', created_at=1721316039, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-lv4C6T43m3ZXCtmBwhwKWPU5', result_files=[], seed=1460983493, status='queued', trained_tokens=None, training_file='file-kn0GWfMTqzbIaCNCLPHjEnNw', validation_file='file-NPRe3mhUVSNJamKi09cioEP5', estimated_finish=None, integrations=[], user_provided_suffix='bpa_itpln')\n",
      "FineTuningJob(id='ftjob-Zjs25G0yacSbt2mTXsf623YP', created_at=1721316039, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-lv4C6T43m3ZXCtmBwhwKWPU5', result_files=[], seed=1460983493, status='queued', trained_tokens=None, training_file='file-kn0GWfMTqzbIaCNCLPHjEnNw', validation_file='file-NPRe3mhUVSNJamKi09cioEP5', estimated_finish=None, integrations=[], user_provided_suffix='bpa_itpln')\n",
      "FineTuningJob(id='ftjob-Zjs25G0yacSbt2mTXsf623YP', created_at=1721316039, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-lv4C6T43m3ZXCtmBwhwKWPU5', result_files=[], seed=1460983493, status='queued', trained_tokens=None, training_file='file-kn0GWfMTqzbIaCNCLPHjEnNw', validation_file='file-NPRe3mhUVSNJamKi09cioEP5', estimated_finish=None, integrations=[], user_provided_suffix='bpa_itpln')\n",
      "FineTuningJob(id='ftjob-Zjs25G0yacSbt2mTXsf623YP', created_at=1721316039, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-lv4C6T43m3ZXCtmBwhwKWPU5', result_files=[], seed=1460983493, status='running', trained_tokens=None, training_file='file-kn0GWfMTqzbIaCNCLPHjEnNw', validation_file='file-NPRe3mhUVSNJamKi09cioEP5', estimated_finish=None, integrations=[], user_provided_suffix='bpa_itpln')\n",
      "FineTuningJob(id='ftjob-Zjs25G0yacSbt2mTXsf623YP', created_at=1721316039, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-lv4C6T43m3ZXCtmBwhwKWPU5', result_files=[], seed=1460983493, status='running', trained_tokens=None, training_file='file-kn0GWfMTqzbIaCNCLPHjEnNw', validation_file='file-NPRe3mhUVSNJamKi09cioEP5', estimated_finish=None, integrations=[], user_provided_suffix='bpa_itpln')\n",
      "FineTuningJob(id='ftjob-Zjs25G0yacSbt2mTXsf623YP', created_at=1721316039, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-lv4C6T43m3ZXCtmBwhwKWPU5', result_files=[], seed=1460983493, status='running', trained_tokens=None, training_file='file-kn0GWfMTqzbIaCNCLPHjEnNw', validation_file='file-NPRe3mhUVSNJamKi09cioEP5', estimated_finish=1721318080, integrations=[], user_provided_suffix='bpa_itpln')\n",
      "FineTuningJob(id='ftjob-Zjs25G0yacSbt2mTXsf623YP', created_at=1721316039, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-lv4C6T43m3ZXCtmBwhwKWPU5', result_files=[], seed=1460983493, status='running', trained_tokens=None, training_file='file-kn0GWfMTqzbIaCNCLPHjEnNw', validation_file='file-NPRe3mhUVSNJamKi09cioEP5', estimated_finish=1721317912, integrations=[], user_provided_suffix='bpa_itpln')\n",
      "FineTuningJob(id='ftjob-Zjs25G0yacSbt2mTXsf623YP', created_at=1721316039, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-lv4C6T43m3ZXCtmBwhwKWPU5', result_files=[], seed=1460983493, status='running', trained_tokens=None, training_file='file-kn0GWfMTqzbIaCNCLPHjEnNw', validation_file='file-NPRe3mhUVSNJamKi09cioEP5', estimated_finish=1721317881, integrations=[], user_provided_suffix='bpa_itpln')\n",
      "FineTuningJob(id='ftjob-Zjs25G0yacSbt2mTXsf623YP', created_at=1721316039, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-lv4C6T43m3ZXCtmBwhwKWPU5', result_files=[], seed=1460983493, status='running', trained_tokens=None, training_file='file-kn0GWfMTqzbIaCNCLPHjEnNw', validation_file='file-NPRe3mhUVSNJamKi09cioEP5', estimated_finish=1721317908, integrations=[], user_provided_suffix='bpa_itpln')\n",
      "FineTuningJob(id='ftjob-Zjs25G0yacSbt2mTXsf623YP', created_at=1721316039, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-lv4C6T43m3ZXCtmBwhwKWPU5', result_files=[], seed=1460983493, status='running', trained_tokens=None, training_file='file-kn0GWfMTqzbIaCNCLPHjEnNw', validation_file='file-NPRe3mhUVSNJamKi09cioEP5', estimated_finish=1721317887, integrations=[], user_provided_suffix='bpa_itpln')\n",
      "FineTuningJob(id='ftjob-Zjs25G0yacSbt2mTXsf623YP', created_at=1721316039, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-lv4C6T43m3ZXCtmBwhwKWPU5', result_files=[], seed=1460983493, status='running', trained_tokens=None, training_file='file-kn0GWfMTqzbIaCNCLPHjEnNw', validation_file='file-NPRe3mhUVSNJamKi09cioEP5', estimated_finish=1721317890, integrations=[], user_provided_suffix='bpa_itpln')\n",
      "FineTuningJob(id='ftjob-Zjs25G0yacSbt2mTXsf623YP', created_at=1721316039, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-lv4C6T43m3ZXCtmBwhwKWPU5', result_files=[], seed=1460983493, status='running', trained_tokens=None, training_file='file-kn0GWfMTqzbIaCNCLPHjEnNw', validation_file='file-NPRe3mhUVSNJamKi09cioEP5', estimated_finish=1721317902, integrations=[], user_provided_suffix='bpa_itpln')\n",
      "FineTuningJob(id='ftjob-Zjs25G0yacSbt2mTXsf623YP', created_at=1721316039, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-lv4C6T43m3ZXCtmBwhwKWPU5', result_files=[], seed=1460983493, status='running', trained_tokens=None, training_file='file-kn0GWfMTqzbIaCNCLPHjEnNw', validation_file='file-NPRe3mhUVSNJamKi09cioEP5', estimated_finish=1721317894, integrations=[], user_provided_suffix='bpa_itpln')\n",
      "FineTuningJob(id='ftjob-Zjs25G0yacSbt2mTXsf623YP', created_at=1721316039, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-lv4C6T43m3ZXCtmBwhwKWPU5', result_files=[], seed=1460983493, status='running', trained_tokens=None, training_file='file-kn0GWfMTqzbIaCNCLPHjEnNw', validation_file='file-NPRe3mhUVSNJamKi09cioEP5', estimated_finish=1721317914, integrations=[], user_provided_suffix='bpa_itpln')\n",
      "FineTuningJob(id='ftjob-Zjs25G0yacSbt2mTXsf623YP', created_at=1721316039, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-lv4C6T43m3ZXCtmBwhwKWPU5', result_files=[], seed=1460983493, status='running', trained_tokens=None, training_file='file-kn0GWfMTqzbIaCNCLPHjEnNw', validation_file='file-NPRe3mhUVSNJamKi09cioEP5', estimated_finish=1721317908, integrations=[], user_provided_suffix='bpa_itpln')\n",
      "FineTuningJob(id='ftjob-Zjs25G0yacSbt2mTXsf623YP', created_at=1721316039, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-lv4C6T43m3ZXCtmBwhwKWPU5', result_files=[], seed=1460983493, status='running', trained_tokens=None, training_file='file-kn0GWfMTqzbIaCNCLPHjEnNw', validation_file='file-NPRe3mhUVSNJamKi09cioEP5', estimated_finish=1721317897, integrations=[], user_provided_suffix='bpa_itpln')\n",
      "FineTuningJob(id='ftjob-Zjs25G0yacSbt2mTXsf623YP', created_at=1721316039, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-lv4C6T43m3ZXCtmBwhwKWPU5', result_files=[], seed=1460983493, status='running', trained_tokens=None, training_file='file-kn0GWfMTqzbIaCNCLPHjEnNw', validation_file='file-NPRe3mhUVSNJamKi09cioEP5', estimated_finish=1721317915, integrations=[], user_provided_suffix='bpa_itpln')\n",
      "FineTuningJob(id='ftjob-Zjs25G0yacSbt2mTXsf623YP', created_at=1721316039, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-lv4C6T43m3ZXCtmBwhwKWPU5', result_files=[], seed=1460983493, status='running', trained_tokens=None, training_file='file-kn0GWfMTqzbIaCNCLPHjEnNw', validation_file='file-NPRe3mhUVSNJamKi09cioEP5', estimated_finish=1721317905, integrations=[], user_provided_suffix='bpa_itpln')\n",
      "FineTuningJob(id='ftjob-Zjs25G0yacSbt2mTXsf623YP', created_at=1721316039, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-lv4C6T43m3ZXCtmBwhwKWPU5', result_files=[], seed=1460983493, status='running', trained_tokens=None, training_file='file-kn0GWfMTqzbIaCNCLPHjEnNw', validation_file='file-NPRe3mhUVSNJamKi09cioEP5', estimated_finish=1721317899, integrations=[], user_provided_suffix='bpa_itpln')\n",
      "FineTuningJob(id='ftjob-Zjs25G0yacSbt2mTXsf623YP', created_at=1721316039, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-lv4C6T43m3ZXCtmBwhwKWPU5', result_files=[], seed=1460983493, status='running', trained_tokens=None, training_file='file-kn0GWfMTqzbIaCNCLPHjEnNw', validation_file='file-NPRe3mhUVSNJamKi09cioEP5', estimated_finish=1721317913, integrations=[], user_provided_suffix='bpa_itpln')\n",
      "FineTuningJob(id='ftjob-Zjs25G0yacSbt2mTXsf623YP', created_at=1721316039, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-lv4C6T43m3ZXCtmBwhwKWPU5', result_files=[], seed=1460983493, status='running', trained_tokens=None, training_file='file-kn0GWfMTqzbIaCNCLPHjEnNw', validation_file='file-NPRe3mhUVSNJamKi09cioEP5', estimated_finish=1721317927, integrations=[], user_provided_suffix='bpa_itpln')\n",
      "FineTuningJob(id='ftjob-Zjs25G0yacSbt2mTXsf623YP', created_at=1721316039, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-lv4C6T43m3ZXCtmBwhwKWPU5', result_files=[], seed=1460983493, status='running', trained_tokens=None, training_file='file-kn0GWfMTqzbIaCNCLPHjEnNw', validation_file='file-NPRe3mhUVSNJamKi09cioEP5', estimated_finish=1721317926, integrations=[], user_provided_suffix='bpa_itpln')\n",
      "FineTuningJob(id='ftjob-Zjs25G0yacSbt2mTXsf623YP', created_at=1721316039, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-lv4C6T43m3ZXCtmBwhwKWPU5', result_files=[], seed=1460983493, status='running', trained_tokens=None, training_file='file-kn0GWfMTqzbIaCNCLPHjEnNw', validation_file='file-NPRe3mhUVSNJamKi09cioEP5', estimated_finish=1721317916, integrations=[], user_provided_suffix='bpa_itpln')\n",
      "FineTuningJob(id='ftjob-Zjs25G0yacSbt2mTXsf623YP', created_at=1721316039, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-lv4C6T43m3ZXCtmBwhwKWPU5', result_files=[], seed=1460983493, status='running', trained_tokens=None, training_file='file-kn0GWfMTqzbIaCNCLPHjEnNw', validation_file='file-NPRe3mhUVSNJamKi09cioEP5', estimated_finish=1721317930, integrations=[], user_provided_suffix='bpa_itpln')\n",
      "FineTuningJob(id='ftjob-Zjs25G0yacSbt2mTXsf623YP', created_at=1721316039, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-lv4C6T43m3ZXCtmBwhwKWPU5', result_files=[], seed=1460983493, status='running', trained_tokens=None, training_file='file-kn0GWfMTqzbIaCNCLPHjEnNw', validation_file='file-NPRe3mhUVSNJamKi09cioEP5', estimated_finish=1721317920, integrations=[], user_provided_suffix='bpa_itpln')\n",
      "FineTuningJob(id='ftjob-Zjs25G0yacSbt2mTXsf623YP', created_at=1721316039, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-lv4C6T43m3ZXCtmBwhwKWPU5', result_files=[], seed=1460983493, status='running', trained_tokens=None, training_file='file-kn0GWfMTqzbIaCNCLPHjEnNw', validation_file='file-NPRe3mhUVSNJamKi09cioEP5', estimated_finish=1721317912, integrations=[], user_provided_suffix='bpa_itpln')\n",
      "FineTuningJob(id='ftjob-Zjs25G0yacSbt2mTXsf623YP', created_at=1721316039, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-lv4C6T43m3ZXCtmBwhwKWPU5', result_files=[], seed=1460983493, status='running', trained_tokens=None, training_file='file-kn0GWfMTqzbIaCNCLPHjEnNw', validation_file='file-NPRe3mhUVSNJamKi09cioEP5', estimated_finish=1721317926, integrations=[], user_provided_suffix='bpa_itpln')\n",
      "FineTuningJob(id='ftjob-Zjs25G0yacSbt2mTXsf623YP', created_at=1721316039, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-lv4C6T43m3ZXCtmBwhwKWPU5', result_files=[], seed=1460983493, status='running', trained_tokens=None, training_file='file-kn0GWfMTqzbIaCNCLPHjEnNw', validation_file='file-NPRe3mhUVSNJamKi09cioEP5', estimated_finish=1721317917, integrations=[], user_provided_suffix='bpa_itpln')\n",
      "FineTuningJob(id='ftjob-Zjs25G0yacSbt2mTXsf623YP', created_at=1721316039, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-3.5-turbo-0125:personal:bpa-itpln:9mNi4124', finished_at=1721317910, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-lv4C6T43m3ZXCtmBwhwKWPU5', result_files=['file-eHiiv6NnxAIKQ63uvu676Zv3'], seed=1460983493, status='succeeded', trained_tokens=87666, training_file='file-kn0GWfMTqzbIaCNCLPHjEnNw', validation_file='file-NPRe3mhUVSNJamKi09cioEP5', estimated_finish=None, integrations=[], user_provided_suffix='bpa_itpln')\n",
      "FineTuningJob(id='ftjob-Zjs25G0yacSbt2mTXsf623YP', created_at=1721316039, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-3.5-turbo-0125:personal:bpa-itpln:9mNi4124', finished_at=1721317910, hyperparameters=Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-lv4C6T43m3ZXCtmBwhwKWPU5', result_files=['file-eHiiv6NnxAIKQ63uvu676Zv3'], seed=1460983493, status='succeeded', trained_tokens=87666, training_file='file-kn0GWfMTqzbIaCNCLPHjEnNw', validation_file='file-NPRe3mhUVSNJamKi09cioEP5', estimated_finish=None, integrations=[], user_provided_suffix='bpa_itpln')\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T16:11:05.472839Z",
     "start_time": "2024-07-18T16:11:04.674685Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check status of fine-tuning job\n",
    "status = client.fine_tuning.jobs.retrieve(fine_tune_id)\n",
    "if status.status == \"succeeded\":\n",
    "    print(\"Model is ready for use!\")\n",
    "    model_id = status.id\n",
    "    model_runtime = status.finished_at - status.created_at\n",
    "    model_trained_tokens = status.trained_tokens\n",
    "    model_hyperparams = status.hyperparameters\n",
    "    model_name = status.fine_tuned_model\n",
    "    model_result_files = status.result_files\n",
    "    print(f\"Model name: {model_name}\")\n",
    "    print(f\"Model runtime: {model_runtime} seconds\")\n",
    "    print(f\"Model trained tokens: {model_trained_tokens}\")\n",
    "    print(f\"Model hyperparameters: {model_hyperparams}\")\n",
    "    print(f\"Model result files: {model_result_files}\")\n",
    "elif status.status == \"running\":\n",
    "    print(\"Model is not ready yet, try again later\")\n",
    "else:\n",
    "    print('status:', status.status)"
   ],
   "id": "bd116dfa17264491",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is ready for use!\n",
      "Model name: ft:gpt-3.5-turbo-0125:personal:bpa-itpln:9mNi4124\n",
      "Model runtime: 1871 seconds\n",
      "Model trained tokens: 87666\n",
      "Model hyperparameters: Hyperparameters(n_epochs=3, batch_size=1, learning_rate_multiplier=2)\n",
      "Model result files: ['file-eHiiv6NnxAIKQ63uvu676Zv3']\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Evaluate the model accuracy",
   "id": "3c820efab026a9ff"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T00:48:26.486025Z",
     "start_time": "2024-07-19T00:47:46.411079Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load test data\n",
    "with open(data_test, 'r') as f:\n",
    "    test_data = [json.loads(line) for line in f]\n",
    "\n",
    "true_responses = []\n",
    "predicted_responses = []\n",
    "\n",
    "# Evaluate model on test data\n",
    "for item in test_data:\n",
    "    messages = item['messages']\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=status.fine_tuned_model,\n",
    "        messages=messages[:-1]  # Exclude the assistant's response\n",
    "    )\n",
    "    \n",
    "    predicted_completion = response.choices[0].message.content.strip()\n",
    "    expected_completion = messages[-1]['content'].strip()\n",
    "    \n",
    "    true_responses.append(expected_completion)\n",
    "    predicted_responses.append(predicted_completion)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(true_responses, predicted_responses)\n",
    "\n",
    "# Calculate precision, recall, and F1-score\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(true_responses, predicted_responses, average='weighted')\n",
    "\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
    "print(f'Precision: {precision * 100:.2f}%')\n",
    "print(f'Recall: {recall * 100:.2f}%')\n",
    "print(f'F1-Score: {f1 * 100:.2f}%')\n"
   ],
   "id": "e345340659795950",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.00%\n",
      "Precision: 0.00%\n",
      "Recall: 0.00%\n",
      "F1-Score: 0.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramadhani.pratama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\ramadhani.pratama\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "77e6deed566feb3b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
